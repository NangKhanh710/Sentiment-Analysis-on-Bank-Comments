{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gL044rw5NB49",
        "outputId": "acd9e4f6-e87f-4306-d2e8-50d0ff10a2d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYsQsWnHLbrN",
        "outputId": "efe60167-632c-4ee9-bc4d-c1766b56fedf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyvi\n",
            "  Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pyvi) (1.2.2)\n",
            "Collecting sklearn-crfsuite (from pyvi)\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (3.2.0)\n",
            "Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite->pyvi)\n",
            "  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (1.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (4.65.0)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.9 pyvi-0.1.1 sklearn-crfsuite-0.3.6\n"
          ]
        }
      ],
      "source": [
        "!pip install pyvi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Embedding, Dense, Dropout, Bidirectional, LSTM, GRU, Input, LayerNormalization, GlobalMaxPooling1D,MaxPooling1D, Conv1D, LayerNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from pyvi import ViUtils\n",
        "from pyvi import ViTokenizer"
      ],
      "metadata": {
        "id": "fgJlUjmDNIF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.Evaluation"
      ],
      "metadata": {
        "id": "70KqD0bIO4Ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score"
      ],
      "metadata": {
        "id": "VfYspXfuN58S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/Sentiment Analysis Model/Data/Bộ test.csv')\n",
        "y_test = pd.read_csv('/content/gdrive/MyDrive/Sentiment Analysis Model/Data/Kiểm thử.csv')\n",
        "df1 = df['none_emoji_review_text'].to_list()"
      ],
      "metadata": {
        "id": "UsSPGTiHNxqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(r\"/content/gdrive/MyDrive/Sentiment Analysis Model/Model/tokenize_data.pkl\",\"rb\") as input_file:\n",
        "  my_tokenizer = pickle.load(input_file)\n",
        "def preprocess_raw_input(raw_input, tokenizer):\n",
        "  input_text_pre = list(tf.keras.preprocessing.text.text_to_word_sequence(raw_input))\n",
        "  input_text_pre = \" \".join(input_text_pre)\n",
        "  input_text_pre_accent = ViTokenizer.tokenize(input_text_pre)\n",
        "  #print('Text preprocessed: ',input_text_pre_accent)\n",
        "  tokenized_data_text = tokenizer.texts_to_sequences([input_text_pre_accent])\n",
        "  vec_data = pad_sequences(tokenized_data_text, padding = 'post', maxlen = 108)#số lượng chiều\n",
        "  return vec_data\n",
        "def inference_model(input_feature, model):\n",
        "  output = model(input_feature).numpy()[0]\n",
        "  result = output.argmax()\n",
        "  conf = float(output.max())\n",
        "  label_dict = {'Tiêu cực':0, 'Trung lập':1, 'Tích cực':2}\n",
        "  label = list(label_dict.keys())\n",
        "  return label[int(result)]\n",
        "\n",
        "def prediction(raw_input, tokenizer, model):\n",
        "  input_model = preprocess_raw_input(raw_input, my_tokenizer)\n",
        "  result = inference_model(input_model, model)\n",
        "  return result\n",
        "\n",
        "\n",
        "BILSTM_model = load_model('/content/gdrive/MyDrive/Sentiment Analysis Model/Model/model_bilstm_1000.h5')\n",
        "CNN_model = load_model('/content/gdrive/MyDrive/Sentiment Analysis Model/Model/model_cnn.h5')\n",
        "Transformer_model = load_model('/content/gdrive/MyDrive/Sentiment Analysis Model/Model/Transformer_model_nh11.h5')\n",
        "\n",
        "#with open(r\"tokenize_data.pkl\",\"rb\") as input_file:\n",
        " # my_tokenizer = pickle.load(input_file)\n"
      ],
      "metadata": {
        "id": "PaQrl_MmNQGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bilstm = []\n",
        "for i in df1:\n",
        "  predict = prediction(i, my_tokenizer,BILSTM_model)\n",
        "  bilstm.append(predict)"
      ],
      "metadata": {
        "id": "GO_--g1TN2lF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = []\n",
        "for i in df1:\n",
        "  predict = prediction(i, my_tokenizer,CNN_model)\n",
        "  cnn.append(predict)"
      ],
      "metadata": {
        "id": "5MsMh8hCOE0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trans = []\n",
        "for i in df1:\n",
        "  predict = prediction(i, my_tokenizer,Transformer_model)\n",
        "  trans.append(predict)"
      ],
      "metadata": {
        "id": "5NDKRXJ6OJFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Điểm mô hình BILSTM\n",
        "print('Điểm: ', accuracy_score(y_test,bilstm))\n",
        "print('Điểm: ', recall_score(y_test,bilstm,average= None))\n",
        "print('Điểm: ', precision_score(y_test,bilstm,average= None))\n",
        "print('Điểm: ', f1_score(y_test,bilstm,average= None))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4nQP7c9ORGR",
        "outputId": "fb079c2b-894b-413b-b39f-b1d07c4362f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Điểm:  0.9587628865979382\n",
            "Điểm:  [1. 0. 1.]\n",
            "Điểm:  [0.95348837 0.         0.96296296]\n",
            "Điểm:  [0.97619048 0.         0.98113208]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Điểm mô hình CNN\n",
        "print('Điểm: ', accuracy_score(y_test,cnn))\n",
        "print('Điểm: ', recall_score(y_test,cnn,average= None))\n",
        "print('Điểm: ', precision_score(y_test,cnn,average= None))\n",
        "print('Điểm: ', f1_score(y_test,cnn,average= None))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVmHG7viOfTa",
        "outputId": "0caefee0-583b-4ee4-a63c-5c371061987c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Điểm:  0.9381443298969072\n",
            "Điểm:  [1.         0.         0.96153846]\n",
            "Điểm:  [0.95348837 0.         0.92592593]\n",
            "Điểm:  [0.97619048 0.         0.94339623]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Điểm mô hình Transformer\n",
        "print('Điểm: ', accuracy_score(y_test,trans))\n",
        "print('Điểm: ', recall_score(y_test,trans,average= None))\n",
        "print('Điểm: ', precision_score(y_test,trans,average= None))\n",
        "print('Điểm: ', f1_score(y_test,trans,average= None))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VM5P_jwOjTk",
        "outputId": "5f0d85e8-b4b2-42f9-f6e6-151edce04bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Điểm:  0.9381443298969072\n",
            "Điểm:  [0.97560976 0.         0.98076923]\n",
            "Điểm:  [0.97560976 0.         0.91071429]\n",
            "Điểm:  [0.97560976 0.         0.94444444]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.Deploying"
      ],
      "metadata": {
        "id": "-ZRMaBfEO7s6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "with open(r\"/content/gdrive/MyDrive/Sentiment Analysis Model/Model/tokenize_data.pkl\",\"rb\") as input_file:\n",
        "  tokenize_data = pickle.load(input_file)\n",
        "def preprocess_raw_input(raw_input, tokenizer):\n",
        "  input_text_pre = list(tf.keras.preprocessing.text.text_to_word_sequence(raw_input))\n",
        "  input_text_pre = \" \".join(input_text_pre)\n",
        "  input_text_pre_accent = ViTokenizer.tokenize(input_text_pre)\n",
        "  print('Text preprocessed: ',input_text_pre_accent)\n",
        "  tokenized_data_text = tokenizer.texts_to_sequences([input_text_pre_accent])\n",
        "  vec_data = pad_sequences(tokenized_data_text, padding = 'post', maxlen = 108)\n",
        "  return vec_data\n",
        "def inference_model(input_feature, model):\n",
        "  output = model(input_feature).numpy()[0]\n",
        "  result = output.argmax()\n",
        "  conf = float(output.max())\n",
        "  label_dict = {'Tiêu cực':0, 'Trung lập':1, 'Tích cực':2}\n",
        "  label = list(label_dict.keys())\n",
        "  return label[int(result)], conf\n",
        "def prediction(raw_input, tokenizer, model):\n",
        "  input_model = preprocess_raw_input(raw_input, tokenize_data)\n",
        "  result, conf = inference_model(input_model, model)\n",
        "  return result, conf\n",
        "\n",
        "#my_model = generate_model()\n",
        "my_model = load_model('/content/gdrive/MyDrive/Sentiment Analysis Model/Model/model_bilstm_1000.h5')\n",
        "\n",
        "with open(r\"/content/gdrive/MyDrive/Sentiment Analysis Model/Model/tokenize_data.pkl\",\"rb\") as input_file:\n",
        "  my_tokenizer = pickle.load(input_file)\n",
        "\n",
        "print(prediction('Nhân viên phục vụ tốt', my_tokenizer,my_model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvnDXsigO-XH",
        "outputId": "9cc577b5-7023-48ed-d8a9-fb558327d36c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text preprocessed:  nhân_viên phục_vụ tốt\n",
            "('Tích cực', 0.8908493518829346)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while(True):\n",
        "  text = input(\"Enter Comment: \")\n",
        "  if text == 'end':\n",
        "        break\n",
        "  else:\n",
        "    print(prediction(text,my_tokenizer,my_model)[0]+\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rSz5CpJPiay",
        "outputId": "bc3cd7a1-36e4-4858-b693-f52fc74c3b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Comment: Thái độ nhân viên cực kì tệ\n",
            "Text preprocessed:  thái_độ nhân_viên cực_kì tệ\n",
            "Tiêu cực\n",
            "\n",
            "Enter Comment: Ngân hàng rất ok\n",
            "Text preprocessed:  ngân_hàng rất ok\n",
            "Tích cực\n",
            "\n",
            "Enter Comment: Tôi không thích đi đến ngân hàng này nữa\n",
            "Text preprocessed:  tôi không thích đi đến ngân_hàng này nữa\n",
            "Tiêu cực\n",
            "\n",
            "Enter Comment: Nhân viên thì chậm chạp, dịch vụ quá tệ\n",
            "Text preprocessed:  nhân_viên thì chậm_chạp dịch_vụ quá tệ\n",
            "Tiêu cực\n",
            "\n",
            "Enter Comment: end\n"
          ]
        }
      ]
    }
  ]
}